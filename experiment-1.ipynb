{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import  ConversationBufferWindowMemory\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up groq api key\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# chat set up\n",
    "GROQ_LLM = ChatGroq(temperature=0.5, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chains\n",
    "\n",
    "- 1. Chat Chain\n",
    "- 2. Chat Reviewer\n",
    "- 3. Requirement Extractor\n",
    "- 4. Problem Search\n",
    "- 5. Code Generation\n",
    "- 6. Code and Requirement Reviewer\n",
    "\n",
    "## Other Functions\n",
    "- 1. Code Saver\n",
    "- 2. Class Generator\n",
    "- 3. Code implementation and data saver.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can override it and set it to \"AI Assistant\"\n",
    "\n",
    "chat_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a Data Science Consultant. You have over 20 years of experience in the field. \n",
    "You are currently working with a client to create a synthetic data for his project. \n",
    "The data is a real world based daa exhibits the same characteristics as the real data.\n",
    "\n",
    "Initially you don't know anything about the project, that's why you want to ask the client some questions to understand the data requirements.\n",
    "This is the work flow you have been following:\n",
    "    1. Initiate a besutiful and interactive sessons with the user.\n",
    "    2. Ask questions about the project the client is working on.\n",
    "    3. Ask for the purpose of this data in relation to the project.\n",
    "    4. Ask for possible columns and the data types. You can also suggest based on the project.\n",
    "    5. After for the intended data size. You can also suggest based on the project. The client can also specify the size.\n",
    "    6. Collate all the information and present back to the client for review.\n",
    "    7. Review thw generated code with the client requirements.\n",
    "    8. After User has verified that all the requirements are met, respond with - ALL REQUIREMENTS RECORDED.\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "AI Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=chat_template)\n",
    "chat_conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=GROQ_LLM,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=10, ai_prefix=\"AI Assistant\"),\n",
    "    output_parser=StrOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a Data Science Consultant. You have over 20 years of experience in the field. \n",
      "You are currently working with a client to create a synthetic data for his project. \n",
      "The data is a real world based daa exhibits the same characteristics as the real data.\n",
      "\n",
      "Initially you don't know anything about the project, that's why you want to ask the client some questions to understand the data requirements.\n",
      "This is the work flow you have been following:\n",
      "    1. Initiate a besutiful and interactive sessons with the user.\n",
      "    2. Ask questions about the project the client is working on.\n",
      "    3. Ask for the purpose of this data in relation to the project.\n",
      "    4. Ask for possible columns and the data types. You can also suggest based on the project.\n",
      "    5. After for the intended data size. You can also suggest based on the project. The client can also specify the size.\n",
      "    6. Collate all the information and present back to the client for review.\n",
      "    7. Review thw generated code with the client requirements.\n",
      "    8. After User has verified that all the requirements are met, respond with - ALL REQUIREMENTS RECORDED.\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to meet you! I'm your Data Science Consultant, and I'll be helping you with creating synthetic data for your project. I'd love to learn more about your project and understand your requirements.\\n\\nCan you please tell me a bit about the project you're working on? What's the main goal or objective of your project?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite Router\n",
    "def chat_reviewer(chat_history: list) -> str:\n",
    "    chat_reviewer = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert at evaluating the conversation between a USER and an AI. \\n\n",
    "        You are checking to see if the AI has already understood the user requirements and if the user approves of it too. \\n\n",
    "\n",
    "        Ask yourself the following questions: \\n\\n\n",
    "\n",
    "        Has the user mentioned all of his requirements?\n",
    "        Has the AI understood the requirements correctly?\n",
    "        Has the AI presented the requirements back to the user for verification?\n",
    "        Has the user approved of the requirements?\n",
    "\n",
    "        Give a binary choice 'understood' (if the requirements has been met)) or 'not_understood' (if the ai still needs more information) based on the chat conversation.\n",
    "        Return only the binary choice and no premable or explaination. \\\n",
    "        Be Sure of your decision before you submit. \\n\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\"],\n",
    "    )\n",
    "\n",
    "    chat_review_router = chat_reviewer | GROQ_LLM | StrOutputParser()\n",
    "    output = chat_review_router.invoke({\"chat_history\":chat_history})\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY = [{\n",
    "    \"messages\": [\n",
    "        {\"user\": \"USER\", \"text\": \"Hi, how are you today?\", \"timestamp\": \"2023-02-02T12:00:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Hello! I'm doing well, thank you for asking. How can I assist you?\", \"timestamp\": \"2023-02-02T12:00:05\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I need to book a flight from New York to Los Angeles on a specific date.\", \"timestamp\": \"2023-02-02T12:10:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I'd be happy to help you with that! What is the specific date you're looking to travel?\", \"timestamp\": \"2023-02-02T12:11:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"February 14th.\", \"timestamp\": \"2023-02-02T12:12:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Let me check availability. Can you please confirm that you'd like to travel on February 14th from New York to Los Angeles?\", \"timestamp\": \"2023-02-02T12:13:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, that's correct.\", \"timestamp\": \"2023-02-02T12:14:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I've found a suitable flight for you. Would you like to book it?\", \"timestamp\": \"2023-02-02T12:15:00\"}\n",
    "    ]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understood\n"
     ]
    }
   ],
   "source": [
    "print(chat_reviewer(CHAT_HISTORY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirement Extractor\n",
    "def requirement_extractor(chat_history: list, chat_review: str) -> dict:\n",
    "    requirement_extractor_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are the Coding Requirement Extraction Agent take the CHAT_HISTORY of a conversation between the USER and AI, the CHAT_REVIEW  \\\n",
    "                which tells if the ai understands the user requirment \\\n",
    "                If the CHAT_REVIEW is 'understood' then extract the code requirement from the chat_history. \\n\n",
    "                \n",
    "                Extract a code requirement in this format:\n",
    "                    1. Problem statement: The problem that the user is trying to solve.\n",
    "                    2. Column names: The columns that the user wants in the data.\n",
    "                    3. Data types: The data types for each column.\n",
    "                    4. Data size: The intended size of the data. This should be the number of rows.\n",
    "                    5. Data Variability: The possible variability in the data as per the user's requirement. This is optional.\n",
    "\n",
    "                \n",
    "                You never make up information that hasn't been provided by the CHAT_HISTORY. \\n\n",
    "                Return the code requirement as a JSON with the keys 'problem_statement', 'column_names', 'data_types', 'data_size', and 'data_variability' if provided. \\n\n",
    "                If the CHAT_REVIEW is 'not_understood' then return 'Nothing-To-Extract' as JSON with a single key 'no_extraction' and no premable or explaination. \\n\n",
    "\n",
    "                \n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\n",
    "        CHAT_REVIEW: {chat_review} \\n\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\",\"chat_review\"],\n",
    "    )\n",
    "\n",
    "    requirement_extraction_chain = requirement_extractor_prompt | GROQ_LLM | JsonOutputParser()\n",
    "    output = requirement_extraction_chain.invoke({\"chat_history\":chat_history, \"chat_review\":chat_review})\n",
    "    return output\n",
    "requirement_extractor_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the Coding Requirement Extraction Agent take the CHAT_HISTORY of a conversation between the USER and AI, the CHAT_REVIEW  \\\n",
    "            which tells if the ai understands the user requirment \\\n",
    "            If the CHAT_REVIEW is 'understood' then extract the code requirement from the chat_history. \\n\n",
    "            \n",
    "            Extract a code requirement in this format:\n",
    "                1. Problem statement: The problem that the user is trying to solve.\n",
    "                2. Column names: The columns that the user wants in the data.\n",
    "                3. Data types: The data types for each column.\n",
    "                4. Data size: The intended size of the data. This should be the number of rows.\n",
    "                5. Data Variability: The possible variability in the data as per the user's requirement. This is optional.\n",
    "\n",
    "            \n",
    "            You never make up information that hasn't been provided by the CHAT_HISTORY. \\n\n",
    "            Return the code requirement as a JSON with the keys 'problem_statement', 'column_names', 'data_types', 'data_size', and 'data_variability' if provided. \\n\n",
    "            If the CHAT_REVIEW is 'not_understood' then return 'Nothing-To-Extract' as JSON with a single key 'no_extraction' and no premable or explaination. \\n\n",
    "\n",
    "            \n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    CHAT_HISTORY: {chat_history} \\n\n",
    "    CHAT_REVIEW: {chat_review} \\n\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"chat_history\",\"chat_review\"],\n",
    ")\n",
    "\n",
    "requirement_extraction_chain = requirement_extractor_prompt | GROQ_LLM | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY =  {\n",
    "    \"messages\": [\n",
    "        {\"user\": \"USER\", \"text\": \"Hi, I'm trying to create a dataset for sales in a city. I'm looking to analyze the sales of fashion products in New York City. I want to track the sales of specific products to understand their market performance.\", \"timestamp\": \"2023-02-10T14:25:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Sounds like an interesting project! Can you please tell me more about what you're trying to achieve? What specific problem are you trying to solve?\", \"timestamp\": \"2023-02-10T14:26:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"The problem I'm trying to solve is to analyze the sales trends of blouses, tops, and dresses in New York City. I want to understand which products are most popular and identify any seasonal patterns.\", \"timestamp\": \"2023-02-10T14:27:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! So, you're looking to analyze sales data for blouses, tops, and dresses in New York City. Can you please list the columns you'd like to include in the dataset?\", \"timestamp\": \"2023-02-10T14:28:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like to include columns for date, product category (blouses, tops, dresses), product sub-category (e.g. long-sleeve blouses), and sales amount.\", \"timestamp\": \"2023-02-10T14:30:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"That makes sense! What data types do you expect for each column? For example, would the sales amount be a numerical value?\", \"timestamp\": \"2023-02-10T14:31:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, the sales amount would be a numerical value. And the date would be a date type. The product categories would be categorical.\", \"timestamp\": \"2023-02-10T14:33:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! For the sales amount, I assume you want a numerical value, such as a float or integer. For the date, I assume it would be a date data type. And for the product categories, I assume it would be a categorical value, such as strings or categorical data types like enum or categorical.\", \"timestamp\": \"2023-02-10T14:34:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, that's correct! I'd also like to know how many rows of data you'd like to generate.\", \"timestamp\": \"2023-02-10T14:35:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I can generate a dataset with a specified number of rows. How many rows would you like the dataset to have?\", \"timestamp\": \"2023-02-10T14:36:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like the dataset to have 10,000 rows.\", \"timestamp\": \"2023-02-10T14:37:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Okay, I'll generate a dataset with 10,000 rows. Would you like to specify any variability in the data?\", \"timestamp\": \"2023-02-10T14:38:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"No, I don't need any variability in the data.\", \"timestamp\": \"2023-02-10T14:39:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Alright, I've generated the dataset with the specified columns, data types, and number of rows. I've excluded variability to ensure consistent data.\", \"timestamp\": \"2023-02-10T14:40:00\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_understood\n"
     ]
    }
   ],
   "source": [
    "chat_review_ = chat_review_router.invoke({\"chat_history\": CHAT_HISTORY})\n",
    "\n",
    "print(chat_review_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_extraction': 'Nothing-To-Extract'}\n"
     ]
    }
   ],
   "source": [
    "print(requirement_extraction_chain.invoke({\"chat_history\": CHAT_HISTORY, \"chat_review\":chat_review_}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draft Code\n",
    "code_generator_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the Data Science Coding Agent. You read the CHAT_HISTORY below, the conversation between the USER and AI. \\\n",
    "    , the CHAT_REVIEW that reviews the chat and tells if the AI understands the USER requirements, \\\n",
    "    the Extracted Requirements from REQUIREMENT_EXTRACTOR.\n",
    "\n",
    "    Here is your task: \\n\n",
    "\n",
    "        1. You write excellent codes for the client based on the Extracted Requirements. \\n\n",
    "        2. Analyze the Extracted Requirements and make sure the code meets the requirements. \\n\n",
    "        3. You can use Pandas, Numpy, or any other library you think is necessary. \\n\n",
    "        4. You are to always ensure that the code is well-documented and easy to understand. \\n\n",
    "        5. Your priority is to write clean, efficient, and effective code that meets the client's requirements. \\n\n",
    "        6. Always check the datatypes compatibility to avoid errors. \\n Use the libraries effectively to generate the data. \\n\n",
    "        7. You are to return the code as a string and no premable or explanation. \\n\n",
    "\n",
    "    Other Informations: \\n\n",
    "        You never make up information that hasn't been provided by the CHAT_HISTORY, CHAT_REVIEW, or REQUIREMENT_EXTRACTOR. \\n\n",
    "        The CHAT_REVIEW is either 'understood' or 'not_understood'. If CHAT_REVIEW is 'understood', \\\n",
    "        the Extracted Requirements will be in the format of a JSON with the keys 'problem_statement', 'column_names', 'data_types', 'data_size', and 'data_variability' if provided. \\\n",
    "\n",
    "        If the CHAT_REVIEW is 'not_understood' then the Extracted Requirements will be 'Nothing-To-Extract' or 'True' as JSON with a single key 'no_extraction'. \\\n",
    "        So when we have 'Nothing-To-Extract' then we don't have any requirements to work with. \\\n",
    "        Else you return 'no-code generated' as a string and no premable or explanation. \\\n",
    "\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    CHAT_HISTORY: {chat_history} \\n\\n\n",
    "    CHAT_REVIEW: {chat_review} \\n\\n\n",
    "    REQUIREMENT_EXTRACTOR: {extracted_requirements} \\n\\n\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"chat_history\",\"chat_review\",\"extracted_requirements\"],\n",
    ")\n",
    "\n",
    "code_generator_chain = code_generator_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understood\n",
      "{'problem_statement': 'Analyze the sales trends of blouses, tops, and dresses in New York City', 'column_names': ['date', 'product_category', 'product_sub_category', 'sales_amount'], 'data_types': {'date': 'date', 'product_category': 'categorical', 'product_sub_category': 'categorical', 'sales_amount': 'numerical'}, 'data_size': 10000, 'data_variability': 'no variability'}\n"
     ]
    }
   ],
   "source": [
    "chat_review_ =  chat_review_router.invoke({\"chat_history\": CHAT_HISTORY})\n",
    "extracted_req = requirement_extraction_chain.invoke({\"chat_history\": CHAT_HISTORY, \"chat_review\":chat_review_})\n",
    "print(chat_review_)\n",
    "print(extracted_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_output = code_generator_chain.invoke({\"chat_history\": CHAT_HISTORY, \"chat_review\":chat_review_, \"extracted_requirements\":extracted_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the code based on the extracted requirements:\n",
      "\n",
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "# Define the column names and their data types\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float'}\n",
      "\n",
      "# Define the data size\n",
      "data_size = 10000\n",
      "\n",
      "# Generate the dataset\n",
      "data = {\n",
      "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "}\n",
      "\n",
      "# Convert the data to a pandas DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Print the generated dataset\n",
      "print(df)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(code_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "code_rewriter_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the Data Science Coding Agent. You read the GENERATED_CODE, and the Extracted Requirements from REQUIREMENT_EXTRACTOR. \\n\n",
    "\n",
    "    Here is your task: \\n\n",
    "\n",
    "      1. Extract the coding part in the GENERATED_CODE. \\n\n",
    "      2. You compare this with the Extracted Requirements, to ensure that the code meets the requirements. \\n\n",
    "      3. You are to check the code for any errors, inconsistencies, or missing requirements. \\n\n",
    "      4. You make a deep search and simulate the code to ensure that it works as expected. For every method used you check to make sure it is correct\\n\n",
    "      5. You are rewriting the code with a 100 percent correctness. \\n\n",
    "      6. You are to return the code as a string and no premable or explanation. \\n\n",
    "      7. You are to ONLY RETURN THE CORRECTED/REWRITTEN CODE. \\n \n",
    "\n",
    "\n",
    "  Make sure you are 100 percent sure of your corrections before you submit. \\n\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    GENERATED_CODE: {generated_code} \\n\\n\n",
    "    REQUIREMENT_EXTRACTOR: {extracted_requirements} \\n\\n\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generated_code\",\"extracted_requirements\"],\n",
    ")\n",
    "\n",
    "code_rewriter_chain = code_rewriter_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewritten_code = code_rewriter_chain.invoke({\"generated_code\": code_output, \"extracted_requirements\":extracted_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "# Define the column names and their data types\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "# Define the data size\n",
      "data_size = 10000\n",
      "\n",
      "# Generate the dataset\n",
      "data = {\n",
      "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "}\n",
      "\n",
      "# Convert the data to a pandas DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Print the generated dataset\n",
      "print(df)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(rewritten_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>sales_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>blouses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>blouses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>tops</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>blouses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>dresses</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2050-05-14</td>\n",
       "      <td>blouses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2050-05-15</td>\n",
       "      <td>tops</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2050-05-16</td>\n",
       "      <td>blouses</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2050-05-17</td>\n",
       "      <td>blouses</td>\n",
       "      <td>tunics</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2050-05-18</td>\n",
       "      <td>tops</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date product_category  product_sub_category  sales_amount\n",
       "0    2023-01-01          blouses   long-sleeve blouses            96\n",
       "1    2023-01-02          blouses               dresses            52\n",
       "2    2023-01-03             tops  short-sleeve blouses            78\n",
       "3    2023-01-04          blouses               dresses            93\n",
       "4    2023-01-05          dresses              t-shirts            98\n",
       "...         ...              ...                   ...           ...\n",
       "9995 2050-05-14          blouses  short-sleeve blouses            43\n",
       "9996 2050-05-15             tops  short-sleeve blouses            48\n",
       "9997 2050-05-16          blouses              t-shirts            63\n",
       "9998 2050-05-17          blouses                tunics            22\n",
       "9999 2050-05-18             tops   long-sleeve blouses            73\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# Define the column names and their data types\n",
    "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
    "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
    "\n",
    "# Define the data size\n",
    "data_size = 10000\n",
    "\n",
    "# Generate the dataset\n",
    "data = {\n",
    "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
    "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
    "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
    "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
    "}\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the generated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "code_extractor_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a Code Extractor Agent. \\n\n",
    "    You take in codes that might have some texts added to it. \\n\n",
    "\n",
    "    Only extract the code and return it as the only output. \\n\n",
    "\n",
    "    Return only the code and nothing added to it.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    CODE: {generated_code} \\n\\n\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generated_code\"],\n",
    ")\n",
    "\n",
    "code_extractor_chain = code_extractor_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_code = code_extractor_chain.invoke({\"generated_code\": rewritten_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "data_size = 10000\n",
      "\n",
      "data = {\n",
      "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "print(df)\n"
     ]
    }
   ],
   "source": [
    "print(extracted_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "code_modifier_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a Coding Agent. You receive from CODES texts that contain a full code that creates a synthetic data for a client. \\n\n",
    "    Your job is to convert this code into a high level Class that has a crate function whereby when called the data is created.\n",
    "    You are returning a high level class that has a create function that creates the data.\n",
    "    This is how you should structure the class:\n",
    "      import the necessary libraries\n",
    "       classname:   SyntheticDataGenerator\n",
    "         method:      create - creates the synthetic data\n",
    "         method: save_to_csv - saves the data to a csv file\n",
    "         method: generate_and_save_data - generates and saves the data to a csv file\n",
    "\n",
    "    Return just the code, no extra text.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    CODEs: {generated_code} \\n\\n\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generated_code\"],\n",
    ")\n",
    "\n",
    "code_modifier_chain = code_modifier_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_code = code_modifier_chain.invoke({\"generated_code\": extracted_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "class SyntheticDataGenerator:\n",
      "    def __init__(self):\n",
      "        self.column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "        self.data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "    def create(self):\n",
      "        data_size = 10000\n",
      "        data = {\n",
      "            'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "            'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "            'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "            'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "        }\n",
      "        return pd.DataFrame(data)\n",
      "\n",
      "    def save_to_csv(self, df, filename):\n",
      "        df.to_csv(filename, index=False)\n",
      "\n",
      "    def generate_and_save_data(self, filename):\n",
      "        df = self.create()\n",
      "        self.save_to_csv(df, filename)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(modified_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Create a Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows\n",
    "data_size = 10000\n",
    "\n",
    "# Create a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through the number of rows\n",
    "for i in range(data_size):\n",
    "    # Generate the date\n",
    "    date_obj = date.fromtimestamp(int(fake.random_int(min=1643728000, max=1646324800)))\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Generate the product category (blouses, tops, dresses)\n",
    "    product_categories = ['blouses', 'tops', 'dresses']\n",
    "    product_category = fake.random_element(elements=product_categories)\n",
    "\n",
    "    # Generate the product sub-category (e.g. long-sleeve blouses)\n",
    "    product_sub_categories = ['long-sleeve blouses', 'short-sleeve blouses', 'tank tops']\n",
    "    product_sub_category = fake.random_element(elements=product_sub_categories)\n",
    "\n",
    "    # Generate the sales amount\n",
    "    sales_amount = fake.random_int(min=10, max=1000)\n",
    "\n",
    "    # Append the data to the list\n",
    "    data.append({\n",
    "        'date': date_str,\n",
    "        'product_category': product_category,\n",
    "        'product_sub_category': product_sub_category,\n",
    "        'sales_amount': sales_amount\n",
    "    })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>sales_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>dresses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>dresses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>blouses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-17</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>tops</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>dresses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>tops</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date product_category  product_sub_category  sales_amount\n",
       "0     2022-02-05          dresses  short-sleeve blouses           812\n",
       "1     2022-02-11          dresses   long-sleeve blouses           133\n",
       "2     2022-02-11          blouses  short-sleeve blouses           833\n",
       "3     2022-03-03          dresses             tank tops           737\n",
       "4     2022-02-17          dresses             tank tops           116\n",
       "...          ...              ...                   ...           ...\n",
       "9995  2022-03-02          dresses             tank tops           304\n",
       "9996  2022-02-25             tops             tank tops            75\n",
       "9997  2022-02-18          dresses             tank tops           245\n",
       "9998  2022-02-22          dresses   long-sleeve blouses           626\n",
       "9999  2022-02-04             tops             tank tops           330\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
