{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import  ConversationBufferWindowMemory\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up groq api key\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# chat set up\n",
    "GROQ_LLM = ChatGroq(temperature=0.5, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chains\n",
    "\n",
    "- 1. Chat Chain\n",
    "- 2. Initiator\n",
    "- 3. Chat Reviewer\n",
    "- 4. Requirement Extractor\n",
    "- 5. Problem Search\n",
    "- 6. Code Generation\n",
    "- 7. Code and Requirement Reviewer\n",
    "\n",
    "## Other Functions\n",
    "- 1. Code Saver\n",
    "- 2. Class Generator\n",
    "- 3. Code implementation and data saver.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can override it and set it to \"AI Assistant\"\n",
    "\n",
    "chat_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a Data Science Consultant. You have over 20 years of experience in the field. \n",
    "You are currently working with a client to create a synthetic data for his project. \n",
    "The data is a real world based daa exhibits the same characteristics as the real data.\n",
    "\n",
    "Initially you don't know anything about the project, that's why you want to ask the client some questions to understand the data requirements.\n",
    "This is the work flow you have been following:\n",
    "    1. Initiate a besutiful and interactive sessons with the user.\n",
    "    2. Ask questions about the project the client is working on.\n",
    "    3. Ask for the purpose of this data in relation to the project.\n",
    "    4. Ask for possible columns and the data types. You can also suggest based on the project.\n",
    "    5. After for the intended data size. You can also suggest based on the project. The client can also specify the size.\n",
    "    6. Collate all the information and present back to the client for review.\n",
    "    7. Review thw generated code with the client requirements.\n",
    "    8. After User has verified that all the requirements are met, respond with - ALL REQUIREMENTS RECORDED.\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "AI Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=chat_template)\n",
    "chat_conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=GROQ_LLM,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=10, ai_prefix=\"AI Assistant\"),\n",
    "    output_parser=StrOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a Data Science Consultant. You have over 20 years of experience in the field. \n",
      "You are currently working with a client to create a synthetic data for his project. \n",
      "The data is a real world based daa exhibits the same characteristics as the real data.\n",
      "\n",
      "Initially you don't know anything about the project, that's why you want to ask the client some questions to understand the data requirements.\n",
      "This is the work flow you have been following:\n",
      "    1. Initiate a besutiful and interactive sessons with the user.\n",
      "    2. Ask questions about the project the client is working on.\n",
      "    3. Ask for the purpose of this data in relation to the project.\n",
      "    4. Ask for possible columns and the data types. You can also suggest based on the project.\n",
      "    5. After for the intended data size. You can also suggest based on the project. The client can also specify the size.\n",
      "    6. Collate all the information and present back to the client for review.\n",
      "    7. Review thw generated code with the client requirements.\n",
      "    8. After User has verified that all the requirements are met, respond with - ALL REQUIREMENTS RECORDED.\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to meet you! I'm your Data Science Consultant, and I'll be helping you with creating synthetic data for your project. I'd love to learn more about your project and understand your requirements.\\n\\nCan you please tell me a bit about the project you're working on? What's the main goal or objective of your project?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiator(chat_history: list) -> str:\n",
    "    initiator_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert at evaluating the conversation between a USER and an AI. \\n\n",
    "        Your focus is on the AI response. You're looking for a place where the AI response has \"ALL REQUIREMENTS RECORDED\" in it. \\n\n",
    "        \n",
    "        If you see \"ALL REQUIREMENTS RECORDED\" in thre AI repsonse:\n",
    "            Return 'START' as your response. \\\n",
    "        Else if it's not there:\n",
    "            Return 'WAIT' as your response\n",
    "        \n",
    "        Do not make assumptions. Stick to the details in the chat. \n",
    "        You can only return \"START\" or \"WAIT\", no other explanation is needed.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\"],\n",
    "    )\n",
    "\n",
    "    initiator_router = initiator_prompt | GROQ_LLM | StrOutputParser()\n",
    "    output = initiator_router.invoke({\"chat_history\":chat_history})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite Router\n",
    "def chat_reviewer(chat_history: list) -> str:\n",
    "    chat_reviewer = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert at evaluating the conversation between a USER and an AI. \\n\n",
    "        You are checking to see if the AI has already understood the user requirements and if the user approves of it too. \\n\n",
    "\n",
    "        Ask yourself the following questions: \\n\\n\n",
    "\n",
    "        Has the user mentioned all of his requirements?\n",
    "        Has the AI understood the requirements correctly?\n",
    "        Has the AI presented the requirements back to the user for verification?\n",
    "        Has the user approved of the requirements?\n",
    "\n",
    "        Give a binary choice 'understood' (if the requirements has been met)) or 'not_understood' (if the ai still needs more information) based on the chat conversation.\n",
    "        Return only the binary choice and no premable or explaination. \\\n",
    "        Be Sure of your decision before you submit. \\n\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\"],\n",
    "    )\n",
    "\n",
    "    chat_review_router = chat_reviewer | GROQ_LLM | StrOutputParser()\n",
    "    output = chat_review_router.invoke({\"chat_history\":chat_history})\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY = [{\n",
    "    \"messages\": [\n",
    "        {\"user\": \"USER\", \"text\": \"Hi, how are you today?\", \"timestamp\": \"2023-02-02T12:00:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Hello! I'm doing well, thank you for asking. How can I assist you?\", \"timestamp\": \"2023-02-02T12:00:05\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I need to book a flight from New York to Los Angeles on a specific date.\", \"timestamp\": \"2023-02-02T12:10:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I'd be happy to help you with that! What is the specific date you're looking to travel?\", \"timestamp\": \"2023-02-02T12:11:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"February 14th.\", \"timestamp\": \"2023-02-02T12:12:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Let me check availability. Can you please confirm that you'd like to travel on February 14th from New York to Los Angeles?\", \"timestamp\": \"2023-02-02T12:13:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, that's correct.\", \"timestamp\": \"2023-02-02T12:14:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I've found a suitable flight for you. Would you like to book it?\", \"timestamp\": \"2023-02-02T12:15:00\"}\n",
    "    ]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understood\n"
     ]
    }
   ],
   "source": [
    "print(chat_reviewer(CHAT_HISTORY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirement Extractor\n",
    "def requirement_extractor(chat_history: list, chat_review: str) -> dict:\n",
    "    requirement_extractor_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are the Coding Requirement Extraction Agent take the CHAT_HISTORY of a conversation between the USER and AI, the CHAT_REVIEW  \\\n",
    "                which tells if the ai understands the user requirment \\\n",
    "                If the CHAT_REVIEW is 'understood' then extract the code requirement from the chat_history. \\n\n",
    "                \n",
    "                Extract a code requirement in this format:\n",
    "                    1. Problem statement: The problem that the user is trying to solve.\n",
    "                    2. Column names: The columns that the user wants in the data.\n",
    "                    3. Data types: The data types for each column.\n",
    "                    4. Data size: The intended size of the data. This should be the number of rows.\n",
    "                    5. Data Variability: The possible variability in the data as per the user's requirement. This is optional.\n",
    "\n",
    "                \n",
    "                You never make up information that hasn't been provided by the CHAT_HISTORY. \\n\n",
    "                Return the code requirement as a JSON with the keys 'problem_statement', 'column_names', 'data_types', 'data_size', and 'data_variability' if provided. \\n\n",
    "                If the CHAT_REVIEW is 'not_understood' then return 'Nothing-To-Extract' as JSON with a single key 'no_extraction' and no premable or explaination. \\n\n",
    "\n",
    "                \n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\n",
    "        CHAT_REVIEW: {chat_review} \\n\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\",\"chat_review\"],\n",
    "    )\n",
    "\n",
    "    requirement_extraction_chain = requirement_extractor_prompt | GROQ_LLM | JsonOutputParser()\n",
    "    output = requirement_extraction_chain.invoke({\"chat_history\":chat_history, \"chat_review\":chat_review})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY =  {\n",
    "    \"messages\": [\n",
    "        {\"user\": \"USER\", \"text\": \"Hi, I'm trying to create a dataset for sales in a city. I'm looking to analyze the sales of fashion products in New York City. I want to track the sales of specific products to understand their market performance.\", \"timestamp\": \"2023-02-10T14:25:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Sounds like an interesting project! Can you please tell me more about what you're trying to achieve? What specific problem are you trying to solve?\", \"timestamp\": \"2023-02-10T14:26:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"The problem I'm trying to solve is to analyze the sales trends of blouses, tops, and dresses in New York City. I want to understand which products are most popular and identify any seasonal patterns.\", \"timestamp\": \"2023-02-10T14:27:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! So, you're looking to analyze sales data for blouses, tops, and dresses in New York City. Can you please list the columns you'd like to include in the dataset?\", \"timestamp\": \"2023-02-10T14:28:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like to include columns for date, product category (blouses, tops, dresses), product sub-category (e.g. long-sleeve blouses), and sales amount.\", \"timestamp\": \"2023-02-10T14:30:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"That makes sense! What data types do you expect for each column? For example, would the sales amount be a numerical value?\", \"timestamp\": \"2023-02-10T14:31:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, the sales amount would be a numerical value. And the date would be a date type. The product categories would be categorical.\", \"timestamp\": \"2023-02-10T14:33:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! For the sales amount, I assume you want a numerical value, such as a float or integer. For the date, I assume it would be a date data type. And for the product categories, I assume it would be a categorical value, such as strings or categorical data types like enum or categorical.\", \"timestamp\": \"2023-02-10T14:34:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, that's correct! I'd also like to know how many rows of data you'd like to generate.\", \"timestamp\": \"2023-02-10T14:35:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I can generate a dataset with a specified number of rows. How many rows would you like the dataset to have?\", \"timestamp\": \"2023-02-10T14:36:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like the dataset to have 10,000 rows.\", \"timestamp\": \"2023-02-10T14:37:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Okay, I'll generate a dataset with 10,000 rows. Would you like to specify any variability in the data?\", \"timestamp\": \"2023-02-10T14:38:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"No, I don't need any variability in the data.\", \"timestamp\": \"2023-02-10T14:39:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Alright, I've generated the dataset with the specified columns, data types, and number of rows. I've excluded variability to ensure consistent data.\", \"timestamp\": \"2023-02-10T14:40:00\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_review_ = chat_review_router.invoke({\"chat_history\": CHAT_HISTORY})\n",
    "\n",
    "# print(chat_review_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem_statement': \"The problem I'm trying to solve is to analyze the sales trends of blouses, tops, and dresses in New York City. I want to understand which products are most popular and identify any seasonal patterns.\", 'column_names': ['date', 'product_category', 'product_sub_category', 'sales_amount'], 'data_types': {'date': 'date', 'product_category': 'categorical', 'product_sub_category': 'categorical', 'sales_amount': 'numerical'}, 'data_size': 10000, 'data_variability': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print(requirement_extractor(CHAT_HISTORY, \"understood\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draft Code\n",
    "def code_generator(chat_history: list, chat_review: str, extracted_requirements: dict) -> str:\n",
    "    code_generator_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are the Data Science Coding Agent. You read the CHAT_HISTORY below, the conversation between the USER and AI. \\\n",
    "        , the CHAT_REVIEW that reviews the chat and tells if the AI understands the USER requirements, \\\n",
    "        the Extracted Requirements from REQUIREMENT_EXTRACTOR.\n",
    "\n",
    "        Here is your task:\n",
    "\n",
    "            1. You write excellent code for the client based on the Extracted Requirements.\n",
    "            2. Analyze the Extracted Requirements and make sure the code meets the requirements.\n",
    "            3. You can use Pandas, Numpy, or any other library you think is necessary.\n",
    "            4. You are to always ensure that the code is well-documented and easy to understand.\n",
    "            5. Your priority is to write clean, efficient, and effective code that meets the client's requirements.\n",
    "            6. Always check the data types compatibility to avoid errors. Use the libraries effectively to generate the data.\n",
    "            7. You are to return the code as a string and no preamble or explanation.\n",
    "\n",
    "            \n",
    "        Other Informations: \\n\n",
    "            You never make up information that hasn't been provided by the CHAT_HISTORY, CHAT_REVIEW, or REQUIREMENT_EXTRACTOR. \\n\n",
    "            The CHAT_REVIEW is either 'understood' or 'not_understood'. If CHAT_REVIEW is 'understood', \\\n",
    "            the Extracted Requirements will be in the format of a JSON with the keys 'problem_statement', 'column_names', 'data_types', 'data_size', and 'data_variability' if provided. \\\n",
    "\n",
    "            If the CHAT_REVIEW is 'not_understood' then the Extracted Requirements will be 'Nothing-To-Extract' or 'True' as JSON with a single key 'no_extraction'. \\\n",
    "            So when we have 'Nothing-To-Extract' then we don't have any requirements to work with. \\\n",
    "            Else you return 'no-code generated' as a string and no premable or explanation. \\\n",
    "\n",
    "\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CHAT_HISTORY: {chat_history} \\n\\n\n",
    "        CHAT_REVIEW: {chat_review} \\n\\n\n",
    "        REQUIREMENT_EXTRACTOR: {extracted_requirements} \\n\\n\n",
    "\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"chat_history\",\"chat_review\",\"extracted_requirements\"],\n",
    "    )\n",
    "\n",
    "    code_generator_chain = code_generator_prompt | GROQ_LLM | StrOutputParser()\n",
    "    output = code_generator_chain.invoke({\"chat_history\":chat_history, \"chat_review\":chat_review, \"extracted_requirements\":extracted_requirements})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understood\n",
      "{'problem_statement': 'Analyze the sales trends of blouses, tops, and dresses in New York City to understand which products are most popular and identify any seasonal patterns.', 'column_names': ['date', 'product_category', 'product_sub_category', 'sales_amount'], 'data_types': {'date': 'date', 'product_category': 'categorical', 'product_sub_category': 'categorical', 'sales_amount': 'float'}, 'data_size': 10000, 'data_variability': 'none'}\n"
     ]
    }
   ],
   "source": [
    "chat_review_ =  chat_reviewer(CHAT_HISTORY)\n",
    "extracted_req = requirement_extractor(CHAT_HISTORY, chat_review_)\n",
    "print(chat_review_)\n",
    "print(extracted_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_output = code_generator(CHAT_HISTORY, chat_review_, extracted_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the code based on the extracted requirements:\n",
      "\n",
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Define the column names and data types\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[ns]', \n",
      "             'product_category': 'category', \n",
      "             'product_sub_category': 'category', \n",
      "             'sales_amount': 'float64'}\n",
      "\n",
      "# Generate the dataset with 10,000 rows\n",
      "data = {'date': pd.date_range(start='2023-01-01', periods=10000), \n",
      "        'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=10000), \n",
      "        'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses', 'rompers'], size=10000), \n",
      "        'sales_amount': np.random.uniform(0, 100, size=10000)}\n",
      "\n",
      "# Convert the data to a pandas DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Set the data types\n",
      "df['date'] = pd.to_datetime(df['date'])\n",
      "df['product_category'] = df['product_category'].astype('category')\n",
      "df['product_sub_category'] = df['product_sub_category'].astype('category')\n",
      "df['sales_amount'] = df['sales_amount'].astype('float64')\n",
      "\n",
      "print(df.head())\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(code_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the column names and data types\n",
    "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
    "data_types = {'date': 'datetime64[ns]', \n",
    "             'product_category': 'category', \n",
    "             'product_sub_category': 'category', \n",
    "             'sales_amount': 'float64'}\n",
    "\n",
    "# Generate the dataset with 10,000 rows\n",
    "data = {'date': pd.date_range(start='2023-01-01', periods=10000), \n",
    "        'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=10000), \n",
    "        'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses', 'rompers'], size=10000), \n",
    "        'sales_amount': np.random.uniform(0, 100, size=10000)}\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the data types\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['product_category'] = df['product_category'].astype('category')\n",
    "df['product_sub_category'] = df['product_sub_category'].astype('category')\n",
    "df['sales_amount'] = df['sales_amount'].astype('float64')\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>sales_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>tops</td>\n",
       "      <td>tunics</td>\n",
       "      <td>64.219674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>40.592222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>dresses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>98.726931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>tops</td>\n",
       "      <td>tunics</td>\n",
       "      <td>40.172002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>tops</td>\n",
       "      <td>tunics</td>\n",
       "      <td>19.924830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2050-05-14</td>\n",
       "      <td>blouses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>11.438736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2050-05-15</td>\n",
       "      <td>blouses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>21.132757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2050-05-16</td>\n",
       "      <td>dresses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>2.121448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2050-05-17</td>\n",
       "      <td>dresses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>4.633319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2050-05-18</td>\n",
       "      <td>dresses</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>23.531746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date product_category  product_sub_category  sales_amount\n",
       "0    2023-01-01             tops                tunics     64.219674\n",
       "1    2023-01-02          dresses               dresses     40.592222\n",
       "2    2023-01-03          dresses               dresses     98.726931\n",
       "3    2023-01-04             tops                tunics     40.172002\n",
       "4    2023-01-05             tops                tunics     19.924830\n",
       "...         ...              ...                   ...           ...\n",
       "9995 2050-05-14          blouses   long-sleeve blouses     11.438736\n",
       "9996 2050-05-15          blouses  short-sleeve blouses     21.132757\n",
       "9997 2050-05-16          dresses  short-sleeve blouses      2.121448\n",
       "9998 2050-05-17          dresses  short-sleeve blouses      4.633319\n",
       "9999 2050-05-18          dresses              t-shirts     23.531746\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "def code_rewriter(generated_code: str, extracted_requirements: dict) -> str:\n",
    "    code_rewriter_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are the Data Science Coding Agent. You read the GENERATED_CODE, and the Extracted Requirements from REQUIREMENT_EXTRACTOR. \\n\n",
    "\n",
    "        Here is your task: \\n\n",
    "\n",
    "            1. Extract the coding part in the GENERATED_CODE. \\n\n",
    "            2. You compare this with the Extracted Requirements, to ensure that the code meets the requirements. \\n\n",
    "            3. You are to check the code for any errors, inconsistencies, or missing requirements. \\n\n",
    "            4. You make a deep search and simulate the code to ensure that it works as expected. For every method used you check to make sure it is correct\\n\n",
    "            5. You are rewriting the code with a 100 percent correctness. \\n\n",
    "            6. You are to return the code as a string and no premable or explanation. \\n\n",
    "            7. You are to ONLY RETURN THE CORRECTED/REWRITTEN CODE. \\n \n",
    "\n",
    "\n",
    "        Make sure you are 100 percent sure of your corrections before you submit. \\n\n",
    "\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        GENERATED_CODE: {generated_code} \\n\\n\n",
    "        REQUIREMENT_EXTRACTOR: {extracted_requirements} \\n\\n\n",
    "\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"generated_code\",\"extracted_requirements\"],\n",
    "    )\n",
    "\n",
    "    code_rewriter_chain = code_rewriter_prompt | GROQ_LLM | StrOutputParser()\n",
    "    output = code_rewriter_chain.invoke({\"generated_code\":generated_code, \"extracted_requirements\":extracted_requirements})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewritten_code = code_rewriter_chain.invoke({\"generated_code\": code_output, \"extracted_requirements\":extracted_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "# Define the column names and their data types\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "# Define the data size\n",
      "data_size = 10000\n",
      "\n",
      "# Generate the dataset\n",
      "data = {\n",
      "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "}\n",
      "\n",
      "# Convert the data to a pandas DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Print the generated dataset\n",
      "print(df)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# print(rewritten_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>sales_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>blouses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>blouses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>tops</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>blouses</td>\n",
       "      <td>dresses</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>dresses</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2050-05-14</td>\n",
       "      <td>blouses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2050-05-15</td>\n",
       "      <td>tops</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2050-05-16</td>\n",
       "      <td>blouses</td>\n",
       "      <td>t-shirts</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2050-05-17</td>\n",
       "      <td>blouses</td>\n",
       "      <td>tunics</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2050-05-18</td>\n",
       "      <td>tops</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date product_category  product_sub_category  sales_amount\n",
       "0    2023-01-01          blouses   long-sleeve blouses            96\n",
       "1    2023-01-02          blouses               dresses            52\n",
       "2    2023-01-03             tops  short-sleeve blouses            78\n",
       "3    2023-01-04          blouses               dresses            93\n",
       "4    2023-01-05          dresses              t-shirts            98\n",
       "...         ...              ...                   ...           ...\n",
       "9995 2050-05-14          blouses  short-sleeve blouses            43\n",
       "9996 2050-05-15             tops  short-sleeve blouses            48\n",
       "9997 2050-05-16          blouses              t-shirts            63\n",
       "9998 2050-05-17          blouses                tunics            22\n",
       "9999 2050-05-18             tops   long-sleeve blouses            73\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# Define the column names and their data types\n",
    "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
    "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
    "\n",
    "# Define the data size\n",
    "data_size = 10000\n",
    "\n",
    "# Generate the dataset\n",
    "data = {\n",
    "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
    "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
    "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
    "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
    "}\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the generated dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "def code_extractor(generated_code:str) -> str:\n",
    "    code_extractor_prompt = PromptTemplate(\n",
    "        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are a Code Extractor Agent. \\n\n",
    "        You take in codes that might have some texts added to it. \\n\n",
    "\n",
    "        Only extract the code and return it as the only output. \\n\n",
    "\n",
    "        Return only the code and nothing added to it.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        CODE: {generated_code} \\n\\n\n",
    "\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"generated_code\"],\n",
    "    )\n",
    "\n",
    "    code_extractor_chain = code_extractor_prompt | GROQ_LLM | StrOutputParser()\n",
    "    output = code_extractor_chain.invoke({\"generated_code\":generated_code})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_code = code_extractor_chain.invoke({\"generated_code\": rewritten_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "data_size = 10000\n",
      "\n",
      "data = {\n",
      "    'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(data_size)],\n",
      "    'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=data_size),\n",
      "    'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=data_size),\n",
      "    'sales_amount': np.random.randint(1, 100, size=data_size)\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "print(df)\n"
     ]
    }
   ],
   "source": [
    "# print(extracted_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite code\n",
    "def code_modifier(generated_code: str) -> str:\n",
    "  code_modifier_prompt = PromptTemplate(\n",
    "      template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "      You are a Coding Agent. You receive from CODES texts that contain a full code that creates a synthetic data for a client. \\n\n",
    "      Your job is to convert this code into a high level Class that has a crate function whereby when called the data is created.\n",
    "      You are returning a high level class that has a create function that creates the data.\n",
    "      This is how you should structure the class:\n",
    "        import the necessary libraries\n",
    "        classname:   SyntheticDataGenerator\n",
    "          method:      create - creates the synthetic data\n",
    "          method: save_to_csv - saves the data to a csv file\n",
    "          method: generate_and_save_data - generates and saves the data to a csv file\n",
    "\n",
    "      Return just the code, no extra text.\n",
    "      <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "      CODEs: {generated_code} \\n\\n\n",
    "\n",
    "      <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "      input_variables=[\"generated_code\"],\n",
    "  )\n",
    "\n",
    "  code_modifier_chain = code_modifier_prompt | GROQ_LLM | StrOutputParser()\n",
    "  output = code_modifier_chain.invoke({\"generated_code\":generated_code})\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_code = code_modifier_chain.invoke({\"generated_code\": extracted_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "class SyntheticDataGenerator:\n",
      "    def __init__(self, data_size=10000):\n",
      "        self.data_size = data_size\n",
      "\n",
      "    def create(self):\n",
      "        column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "        data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "        data = {\n",
      "            'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(self.data_size)],\n",
      "            'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=self.data_size),\n",
      "            'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=self.data_size),\n",
      "            'sales_amount': np.random.randint(1, 100, size=self.data_size)\n",
      "        }\n",
      "\n",
      "        self.df = pd.DataFrame(data)\n",
      "\n",
      "    def save_to_csv(self, filename):\n",
      "        self.df.to_csv(filename, index=False)\n",
      "\n",
      "    def generate_and_save_data(self, filename):\n",
      "        self.create()\n",
      "        self.save_to_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "print(modified_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cleaner\n",
    "def remove_triple_quotes(text):\n",
    "    if (text.startswith(\"'''\") and text.endswith(\"'''\")) or (text.startswith(\"```\") and text.endswith(\"```\")):\n",
    "        return text[3:-3]  # Remove triple quotes from both ends\n",
    "    elif text.startswith(\"'''\") or text.startswith(\"```\"):\n",
    "        return text[3:]  # Remove triple quotes from the beginning\n",
    "    elif text.endswith(\"'''\") or text.endswith(\"```\"):\n",
    "        return text[:-3]  # Remove triple quotes from the end\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "cleaned_code = remove_triple_quotes(modified_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "\n",
      "class SyntheticDataGenerator:\n",
      "    def __init__(self, data_size=10000):\n",
      "        self.data_size = data_size\n",
      "\n",
      "    def create(self):\n",
      "        column_names = ['date', 'product_category', 'product_sub_category', 'sales_amount']\n",
      "        data_types = {'date': 'datetime64[D]', 'product_category': 'category', 'product_sub_category': 'category', 'sales_amount': 'float64'}\n",
      "\n",
      "        data = {\n",
      "            'date': [dt.datetime(2023, 1, 1) + dt.timedelta(days=i) for i in range(self.data_size)],\n",
      "            'product_category': np.random.choice(['blouses', 'tops', 'dresses'], size=self.data_size),\n",
      "            'product_sub_category': np.random.choice(['long-sleeve blouses', 'short-sleeve blouses', 'tunics', 't-shirts', 'dresses'], size=self.data_size),\n",
      "            'sales_amount': np.random.randint(1, 100, size=self.data_size)\n",
      "        }\n",
      "\n",
      "        self.df = pd.DataFrame(data)\n",
      "\n",
      "    def save_to_csv(self, filename):\n",
      "        self.df.to_csv(filename, index=False)\n",
      "\n",
      "    def generate_and_save_data(self, filename):\n",
      "        self.create()\n",
      "        self.save_to_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code saver\n",
    "def code_saver(code, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_saver(cleaned_code, \"synthetic_data_generator.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_excecutor\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "file_path = 'synthetic_data_generator.py'\n",
    "def code_executor():\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            # importing the class from the file\n",
    "            from synthetic_data_generator import SyntheticDataGenerator\n",
    "\n",
    "            # creating an instance of the class\n",
    "            data = SyntheticDataGenerator()\n",
    "\n",
    "            # calling the create function\n",
    "            data.generate_and_save_data('data.csv')\n",
    "\n",
    "            return \"Data generated successfully!\"\n",
    "        except Exception as e:\n",
    "        # Capture the complete error, including the traceback\n",
    "            error = {\n",
    "                \"error\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "                # saving the error in a json file\n",
    "            with open('error.json', 'w') as f:\n",
    "                json.dump(error, f)\n",
    "            \n",
    "            return 'Error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data generated successfully!'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_executor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_HISTORY =  {\n",
    "    \"messages\": [\n",
    "        {\"user\": \"USER\", \"text\": \"Hi, I'm trying to create a dataset for sales in a city. I'm looking to analyze the sales of fashion products in New York City. I want to track the sales of specific products to understand their market performance.\", \"timestamp\": \"2023-02-10T14:25:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Sounds like an interesting project! Can you please tell me more about what you're trying to achieve? What specific problem are you trying to solve?\", \"timestamp\": \"2023-02-10T14:26:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"The problem I'm trying to solve is to analyze the sales trends of blouses, tops, and dresses in New York City. I want to understand which products are most popular and identify any seasonal patterns.\", \"timestamp\": \"2023-02-10T14:27:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! So, you're looking to analyze sales data for blouses, tops, and dresses in New York City. Can you please list the columns you'd like to include in the dataset?\", \"timestamp\": \"2023-02-10T14:28:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like to include columns for date, product category (blouses, tops, dresses), product sub-category (e.g. long-sleeve blouses), and sales amount.\", \"timestamp\": \"2023-02-10T14:30:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"That makes sense! What data types do you expect for each column? For example, would the sales amount be a numerical value?\", \"timestamp\": \"2023-02-10T14:31:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, the sales amount would be a numerical value. And the date would be a date type. The product categories would be categorical.\", \"timestamp\": \"2023-02-10T14:33:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Got it! For the sales amount, I assume you want a numerical value, such as a float or integer. For the date, I assume it would be a date data type. And for the product categories, I assume it would be a categorical value, such as strings or categorical data types like enum or categorical.\", \"timestamp\": \"2023-02-10T14:34:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"Yes, that's correct! I'd also like to know how many rows of data you'd like to generate.\", \"timestamp\": \"2023-02-10T14:35:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"I can generate a dataset with a specified number of rows. How many rows would you like the dataset to have?\", \"timestamp\": \"2023-02-10T14:36:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"I'd like the dataset to have 10,000 rows.\", \"timestamp\": \"2023-02-10T14:37:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Okay, I'll generate a dataset with 10,000 rows. Would you like to specify any variability in the data?\", \"timestamp\": \"2023-02-10T14:38:00\"},\n",
    "        {\"user\": \"USER\", \"text\": \"No, I don't need any variability in the data.\", \"timestamp\": \"2023-02-10T14:39:00\"},\n",
    "        {\"ai\": \"AI\", \"text\": \"Alright, I've generated the dataset with the specified columns, data types, and number of rows. I've excluded variability to ensure consistent data. ALL REQUIREMENTS RECORDED\", \"timestamp\": \"2023-02-10T14:40:00\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n"
     ]
    }
   ],
   "source": [
    "print(initiator(CHAT_HISTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Generator(CHAT_HISTORY: list) -> str:\n",
    "    # Initiating the flow\n",
    "    initiation_ = initiator(CHAT_HISTORY)\n",
    "    print(initiation_)\n",
    "    if initiation_ == \"START\":\n",
    "        # Now proceeding with the chat flow\n",
    "        try:\n",
    "            # chat_reviewer section to review chats\n",
    "            chat_review_ = chat_reviewer(CHAT_HISTORY)\n",
    "            # Project Requirement Extractor\n",
    "            extracted_req = requirement_extractor(CHAT_HISTORY, chat_review_)\n",
    "            # Python Code Generator\n",
    "            code_output = code_generator(CHAT_HISTORY, chat_review_, extracted_req)\n",
    "            # Extracting only the code\n",
    "            extracted_code = code_extractor(code_output)\n",
    "            # Modifying the code into classes\n",
    "            modified_code = code_modifier(extracted_code)\n",
    "            # Removing backstrings from the code\n",
    "            cleaned_code = remove_triple_quotes(modified_code)\n",
    "            # saving the cleaned code\n",
    "            code_saver(cleaned_code, \"synthetic_data_generator.py\")\n",
    "            # Exxecuting the codes\n",
    "            execute = code_executor()\n",
    "            return execute\n",
    "        except Exception as e:\n",
    "        # Capture the complete error, including the traceback\n",
    "            error = {\n",
    "                \"error\": str(e),\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "                # saving the error in a json file\n",
    "            with open('error.json', 'w') as f:\n",
    "                json.dump(error, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Data generated successfully!\n"
     ]
    }
   ],
   "source": [
    "print(Data_Generator(CHAT_HISTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Name: Sara Hall\n",
      "Fake Address: 19553 Dana Knoll Suite 321\n",
      "Port Rodney, AK 07353\n",
      "Fake Email: dyoung@example.org\n",
      "Fake Date of Birth: 1969-07-21\n",
      "Random Date: 1981-07-23\n",
      "Random Number (5 digits): 71356\n",
      "Fake Phone Number: +1-534-673-2815x0712\n",
      "Fake Company Name: Smith, Lee and Lucas\n",
      "Fake Text (max 200 characters): Buy he rest language hard realize soon. Sound act boy player carry season. Actually just office even.\n",
      "Guy listen bar think resource. Defense line less turn season low. Deal seat success.\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Create an instance of Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate a fake name\n",
    "print(\"Fake Name:\", fake.name())\n",
    "\n",
    "# Generate a fake address\n",
    "print(\"Fake Address:\", fake.address())\n",
    "\n",
    "# Generate a fake email\n",
    "print(\"Fake Email:\", fake.email())\n",
    "\n",
    "# Generate a fake date of birth within a specific age range (18 to 90 years old)\n",
    "print(\"Fake Date of Birth:\", fake.date_of_birth(minimum_age=18, maximum_age=90))\n",
    "\n",
    "# Generate a random date\n",
    "print(\"Random Date:\", fake.date())\n",
    "\n",
    "# Generate a random number with 5 digits\n",
    "print(\"Random Number (5 digits):\", fake.random_number(digits=5))\n",
    "\n",
    "# Generate a fake phone number\n",
    "print(\"Fake Phone Number:\", fake.phone_number())\n",
    "\n",
    "# Generate a fake company name\n",
    "print(\"Fake Company Name:\", fake.company())\n",
    "\n",
    "# Generate a block of text with a maximum of 200 characters\n",
    "print(\"Fake Text (max 200 characters):\", fake.text(max_nb_chars=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Date within Range (2020-01-01 to 2021-01-01): 2020-08-27 02:28:10\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake date within a specific range (e.g., between 2020-01-01 and 2021-01-01)\n",
    "from datetime import datetime\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2021, 1, 1)\n",
    "fake_date_within_range = fake.date_time_between_dates(datetime_start=start_date, datetime_end=end_date)\n",
    "print(\"Fake Date within Range (2020-01-01 to 2021-01-01):\", fake_date_within_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data has been saved successfully to synthetic_data.py.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Create a Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows\n",
    "data_size = 10000\n",
    "\n",
    "# Create a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through the number of rows\n",
    "for i in range(data_size):\n",
    "    # Generate the date\n",
    "    date_obj = date.fromtimestamp(int(fake.random_int(min=1643728000, max=1646324800)))\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Generate the product category (blouses, tops, dresses)\n",
    "    product_categories = ['blouses', 'tops', 'dresses']\n",
    "    product_category = fake.random_element(elements=product_categories)\n",
    "\n",
    "    # Generate the product sub-category (e.g. long-sleeve blouses)\n",
    "    product_sub_categories = ['long-sleeve blouses', 'short-sleeve blouses', 'tank tops']\n",
    "    product_sub_category = fake.random_element(elements=product_sub_categories)\n",
    "\n",
    "    # Generate the sales amount\n",
    "    sales_amount = fake.random_int(min=10, max=1000)\n",
    "\n",
    "    # Append the data to the list\n",
    "    data.append({\n",
    "        'date': date_str,\n",
    "        'product_category': product_category,\n",
    "        'product_sub_category': product_sub_category,\n",
    "        'sales_amount': sales_amount\n",
    "    })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>sales_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>dresses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>dresses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>blouses</td>\n",
       "      <td>short-sleeve blouses</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-17</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>tops</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>dresses</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>dresses</td>\n",
       "      <td>long-sleeve blouses</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>tops</td>\n",
       "      <td>tank tops</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date product_category  product_sub_category  sales_amount\n",
       "0     2022-02-05          dresses  short-sleeve blouses           812\n",
       "1     2022-02-11          dresses   long-sleeve blouses           133\n",
       "2     2022-02-11          blouses  short-sleeve blouses           833\n",
       "3     2022-03-03          dresses             tank tops           737\n",
       "4     2022-02-17          dresses             tank tops           116\n",
       "...          ...              ...                   ...           ...\n",
       "9995  2022-03-02          dresses             tank tops           304\n",
       "9996  2022-02-25             tops             tank tops            75\n",
       "9997  2022-02-18          dresses             tank tops           245\n",
       "9998  2022-02-22          dresses   long-sleeve blouses           626\n",
       "9999  2022-02-04             tops             tank tops           330\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
